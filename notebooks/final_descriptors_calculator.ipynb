{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /home/cepatinog/amplab/apps/playlist_data\n",
      "Found 2100 processed feature JSON files.\n",
      "Final descriptors saved to CSV: /home/cepatinog/amplab/apps/playlist_data/final_descriptors.csv\n",
      "Final descriptors saved to TSV: /home/cepatinog/amplab/apps/playlist_data/final_descriptors.tsv\n",
      "Sample final descriptors:\n",
      "[{'arousal': 5.800262928009033,\n",
      "  'danceability_classifier': 0.9986696243286133,\n",
      "  'danceability_signal': 1.0441495180130005,\n",
      "  'file': '/home/cepatinog/amplab/data/raw/audio_chunks/audio.003/3K/3KyMDgZ2FewZ6XyHuZWs0K.mp3',\n",
      "  'key': 'F',\n",
      "  'parent_genre': 'Hip Hop',\n",
      "  'predicted_genre': 'Hip Hop---Hardcore Hip-Hop',\n",
      "  'scale': 'major',\n",
      "  'tempo_global_bpm': 186.0,\n",
      "  'valence': 4.255828857421875,\n",
      "  'voice_instrumental': 'voice'},\n",
      " {'arousal': 5.202495574951172,\n",
      "  'danceability_classifier': 0.918759822845459,\n",
      "  'danceability_signal': 1.1787617206573486,\n",
      "  'file': '/home/cepatinog/amplab/data/raw/audio_chunks/audio.000/78/78TuGqFPPpC2rwCAewWeRW.mp3',\n",
      "  'key': 'G',\n",
      "  'parent_genre': 'Electronic',\n",
      "  'predicted_genre': 'Electronic---Downtempo',\n",
      "  'scale': 'major',\n",
      "  'tempo_global_bpm': 106.0,\n",
      "  'valence': 5.148846626281738,\n",
      "  'voice_instrumental': 'instrumental'},\n",
      " {'arousal': 6.014383316040039,\n",
      "  'danceability_classifier': 0.8306550979614258,\n",
      "  'danceability_signal': 1.2326278686523438,\n",
      "  'file': '/home/cepatinog/amplab/data/raw/audio_chunks/audio.000/48/48fPdAwGVoSkGK8GSez9yx.mp3',\n",
      "  'key': 'F',\n",
      "  'parent_genre': 'Electronic',\n",
      "  'predicted_genre': 'Electronic---Synth-pop',\n",
      "  'scale': 'minor',\n",
      "  'tempo_global_bpm': 120.0,\n",
      "  'valence': 4.7871527671813965,\n",
      "  'voice_instrumental': 'voice'},\n",
      " {'arousal': 4.357347011566162,\n",
      "  'danceability_classifier': 0.9995463490486145,\n",
      "  'danceability_signal': 1.1683260202407837,\n",
      "  'file': '/home/cepatinog/amplab/data/raw/audio_chunks/audio.000/1s/1srYUb9mTfIy6sXz7CSDVw.mp3',\n",
      "  'key': 'C',\n",
      "  'parent_genre': 'Hip Hop',\n",
      "  'predicted_genre': 'Hip Hop---Cloud Rap',\n",
      "  'scale': 'minor',\n",
      "  'tempo_global_bpm': 75.0,\n",
      "  'valence': 3.1755707263946533,\n",
      "  'voice_instrumental': 'voice'},\n",
      " {'arousal': 4.087998390197754,\n",
      "  'danceability_classifier': 0.9851526021957397,\n",
      "  'danceability_signal': 1.1625767946243286,\n",
      "  'file': '/home/cepatinog/amplab/data/raw/audio_chunks/audio.006/3D/3DaCTypK2EOxuDZStB2fNN.mp3',\n",
      "  'key': 'A',\n",
      "  'parent_genre': 'Electronic',\n",
      "  'predicted_genre': 'Electronic---Tropical House',\n",
      "  'scale': 'major',\n",
      "  'tempo_global_bpm': 78.0,\n",
      "  'valence': 4.250083923339844,\n",
      "  'voice_instrumental': 'voice'}]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "from config import (\n",
    "    PROCESSED_FEATURES_DIR, EMB_DISCOGS_MODEL_JSON, PROJECT_ROOT\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Create an output directory for our final descriptor files inside the apps folder.\n",
    "output_dir = os.path.join(PROJECT_ROOT, \"apps\", \"playlist_data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(\"Output directory:\", output_dir)\n",
    "\n",
    "\n",
    "# Use the processed features directory from config.\n",
    "processed_features_dir = PROCESSED_FEATURES_DIR\n",
    "\n",
    "# Path to your discogs-effnet metadata JSON file (contains the 400 classes).\n",
    "discogs_metadata_file = EMB_DISCOGS_MODEL_JSON\n",
    "\n",
    "with open(discogs_metadata_file, \"r\") as f:\n",
    "    discogs_metadata = json.load(f)\n",
    "\n",
    "genre_classes = discogs_metadata.get(\"classes\", [])\n",
    "if len(genre_classes) != 400:\n",
    "    print(\"Warning: Expected 400 genre classes, but found\", len(genre_classes))\n",
    "\n",
    "def predict_genre(activation_vector, classes):\n",
    "    \"\"\"\n",
    "    Given a 400-dimensional activation vector, return the genre label corresponding\n",
    "    to the maximum activation.\n",
    "    \"\"\"\n",
    "    if activation_vector and len(activation_vector) == len(classes):\n",
    "        idx = int(np.argmax(activation_vector))\n",
    "        return classes[idx]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "final_rows = []\n",
    "json_files = glob.glob(os.path.join(processed_features_dir, \"*.json\"))\n",
    "print(f\"Found {len(json_files)} processed feature JSON files.\")\n",
    "\n",
    "for jf in json_files:\n",
    "    try:\n",
    "        with open(jf, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {jf}: {e}\")\n",
    "        continue\n",
    "\n",
    "    row = {}\n",
    "    # File path (as stored in the JSON)\n",
    "    row[\"file\"] = data.get(\"file\", \"\")\n",
    "    # Tempo (global BPM)\n",
    "    row[\"tempo_global_bpm\"] = data.get(\"tempo_global_bpm\", None)\n",
    "    # Voice/Instrumental: extract predicted class from \"voice_instrumental\"\n",
    "    vi = data.get(\"voice_instrumental\", None)\n",
    "    if isinstance(vi, dict):\n",
    "        row[\"voice_instrumental\"] = vi.get(\"predicted_class\", None)\n",
    "    else:\n",
    "        row[\"voice_instrumental\"] = vi\n",
    "    # Danceability (Signal-based)\n",
    "    ds = data.get(\"danceability_signal\", None)\n",
    "    if isinstance(ds, dict):\n",
    "        row[\"danceability_signal\"] = ds.get(\"danceability\", None)\n",
    "    else:\n",
    "        row[\"danceability_signal\"] = None\n",
    "    # Danceability (Classifier): probability for \"danceable\"\n",
    "    dc = data.get(\"danceability_classifier\", None)\n",
    "    if isinstance(dc, dict):\n",
    "        dc_vals = dc.get(\"danceability_classifier\", None)\n",
    "        row[\"danceability_classifier\"] = dc_vals[0] if isinstance(dc_vals, list) and len(dc_vals) > 0 else None\n",
    "    else:\n",
    "        row[\"danceability_classifier\"] = None\n",
    "    # Emotion: arousal and valence\n",
    "    emo = data.get(\"arousal_valence\", None)\n",
    "    if isinstance(emo, dict):\n",
    "        row[\"arousal\"] = emo.get(\"arousal\", None)\n",
    "        row[\"valence\"] = emo.get(\"valence\", None)\n",
    "    else:\n",
    "        row[\"arousal\"] = None\n",
    "        row[\"valence\"] = None\n",
    "    # Key and Scale (using the Temperley profile)\n",
    "    row[\"key\"] = data.get(\"temperley_key\", None)\n",
    "    row[\"scale\"] = data.get(\"temperley_scale\", None)\n",
    "    # Genre: use \"predicted_genre\" if available; otherwise, compute from \"genre_activations\"\n",
    "    if \"predicted_genre\" in data:\n",
    "        row[\"predicted_genre\"] = data[\"predicted_genre\"]\n",
    "    else:\n",
    "        acts = data.get(\"genre_activations\", None)\n",
    "        row[\"predicted_genre\"] = predict_genre(acts, genre_classes) if acts else None\n",
    "    # Parent Genre: extract the broad category by splitting on '---'\n",
    "    if row[\"predicted_genre\"]:\n",
    "        row[\"parent_genre\"] = row[\"predicted_genre\"].split('---')[0].strip()\n",
    "    else:\n",
    "        row[\"parent_genre\"] = None\n",
    "\n",
    "    # Do NOT include embeddings here.\n",
    "    final_rows.append(row)\n",
    "\n",
    "# Create the final DataFrame (without embeddings)\n",
    "final_df = pd.DataFrame(final_rows, columns=[\n",
    "    \"file\",\n",
    "    \"tempo_global_bpm\",\n",
    "    \"voice_instrumental\",\n",
    "    \"danceability_signal\",\n",
    "    \"danceability_classifier\",\n",
    "    \"arousal\",\n",
    "    \"valence\",\n",
    "    \"key\",\n",
    "    \"scale\",\n",
    "    \"parent_genre\",\n",
    "    \"predicted_genre\"\n",
    "])\n",
    "\n",
    "# Save final descriptors to CSV and TSV in the output directory.\n",
    "csv_path = os.path.join(output_dir, \"final_descriptors.csv\")\n",
    "final_df.to_csv(csv_path, index=False)\n",
    "print(\"Final descriptors saved to CSV:\", csv_path)\n",
    "\n",
    "tsv_path = os.path.join(output_dir, \"final_descriptors.tsv\")\n",
    "final_df.to_csv(tsv_path, index=False, sep=\"\\t\")\n",
    "print(\"Final descriptors saved to TSV:\", tsv_path)\n",
    "\n",
    "print(\"Sample final descriptors:\")\n",
    "pprint(final_df.head(5).to_dict(orient=\"records\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to CSV: /home/cepatinog/amplab/apps/playlist_data/final_embeddings.csv\n",
      "Embeddings saved to TSV: /home/cepatinog/amplab/apps/playlist_data/final_embeddings.tsv\n"
     ]
    }
   ],
   "source": [
    "import os, glob, json\n",
    "import pandas as pd\n",
    "\n",
    "# Use the same processed_features_dir and json_files list.\n",
    "json_files = glob.glob(os.path.join(processed_features_dir, \"*.json\"))\n",
    "\n",
    "embedding_rows = []\n",
    "for jf in json_files:\n",
    "    try:\n",
    "        with open(jf, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {jf}: {e}\")\n",
    "        continue\n",
    "    row = {}\n",
    "    row[\"file\"] = data.get(\"file\", \"\")\n",
    "    # Get the Discogs embedding and store as a JSON string (if present)\n",
    "    emb_disc = data.get(\"emb_discogs\", None)\n",
    "    row[\"emb_discogs\"] = json.dumps(emb_disc) if emb_disc is not None else None\n",
    "    # Get the MSD embedding and store as a JSON string (if present)\n",
    "    emb_msd = data.get(\"emb_msd\", None)\n",
    "    row[\"emb_msd\"] = json.dumps(emb_msd) if emb_msd is not None else None\n",
    "    embedding_rows.append(row)\n",
    "\n",
    "# Create a single DataFrame with both embeddings.\n",
    "embeddings_df = pd.DataFrame(embedding_rows, columns=[\"file\", \"emb_discogs\", \"emb_msd\"])\n",
    "\n",
    "# Save the embeddings DataFrame to CSV and TSV in the output directory.\n",
    "emb_csv_path = os.path.join(output_dir, \"final_embeddings.csv\")\n",
    "embeddings_df.to_csv(emb_csv_path, index=False)\n",
    "print(\"Embeddings saved to CSV:\", emb_csv_path)\n",
    "\n",
    "emb_tsv_path = os.path.join(output_dir, \"final_embeddings.tsv\")\n",
    "embeddings_df.to_csv(emb_tsv_path, index=False, sep=\"\\t\")\n",
    "print(\"Embeddings saved to TSV:\", emb_tsv_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amplab_essentia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
